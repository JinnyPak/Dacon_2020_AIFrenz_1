{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 프로세스 \n",
    "    - 편의상 X00-39는 X, Y00-17은 Y1, Y18은 Y2라 하겠음\n",
    "1. 데이터 전처리\n",
    "    (1) 표준화\n",
    "        - standard\n",
    "        - MinMax\n",
    "        - Robust :아웃라이어의 영향을 최소화한 기법이다. 중앙값(median)과 IQR(interquartile range)을 사용하기 \n",
    "        때문에 StandardScaler와 비교해보면 표준화 후 동일한 값을 더 넓게 분포 시키고 있음을 확인 할 수 있다.\n",
    "        IQR = Q3 - Q1 : 즉, 25퍼센타일과 75퍼센타일의 값들을 다룬다.\n",
    "    (2) 이상치 처리 : 아니 근데....이상치 넘 많은데 어떡함..\n",
    "        1)\tOne-class SVM :처음 관측 분포의 윤곽선을 새로운 차원 공간에 그려 놓고 추가 관측치가 경계로부터 \n",
    "            구분된 공간 내에 있으면 초기 관측치와 같은 집단, 그렇지 않으면 비정상 데이터라고 간주한다.\n",
    "        2)\tFitting an elliptic envelope : 이 방법론은 데이터 분포에 대한 가정이 필요하다. inlier 데이터가 \n",
    "            가우스 분포라고 가정하면 inlie 위치 및 공분산을 추정할 수 있다. \n",
    "            이렇게 얻은 Mahalanobis distances는 외도 측정을 유도하는데 사용한다.\n",
    "        3)\tIsolation Forest :다차원 데이터셋에서 효율적으로 작동하는 아웃라이어 제거 방법이다. \n",
    "            Isolation Forest는 랜덤하게 선택된 Feature의 MinMax값을 랜덤하게 분리한 관측치들로 구성된다.\n",
    "        4)\tLocal Outlier Factor :이 방법 역시 다차원 데이터의 아웃라이어 제거에 효과적이다.알고리즘은 \n",
    "            관측치의 비정상적인 정도를 반영하는 점수(로컬 아웃 라이어 계수)를 계산한다.주어진 데이터 포인트의 \n",
    "            이웃에 대한 로컬 밀도 편차를 측정한 후 이웃들보다 밀도가 훨씬 낮은 샘플을 감지하는 것이다. \n",
    "            강점은 데이터 세트의 로컬 및 전역 속성을 모두 고려한다는 것이다. \n",
    "            정상 샘플의 기본 밀도가 다른 데이터 세트에서도 성능이 뛰어나다. \n",
    "            표본이 얼마나 고립되어 있는가가 아니라 주위의 이웃에 대해 얼마나 고립되어 있는지를 판단하는 것이다.\n",
    "     (3) Resampling the Dataset\n",
    "    - Oversampling (no inofromation loss, perform better than undersampling, but overfitting issues)\n",
    "    - Undersampling (help improve run time and storage problems, but information loss, biased dataset)\n",
    "    - Generate Synthetic Samples\n",
    "2. 변수 선택\n",
    "    - Univariate Selection (T-test, ANOVA, Coefficient and so on)\n",
    "    - Feature Importance (from Tree-based model)\n",
    "    - RFE (recursive feature elimination)\n",
    "    \n",
    "3. 모델링\n",
    "4. 예측\n",
    " \n",
    "#### 실패한 방법 \n",
    "---------------------------------------------------------------\n",
    "1. model.fit(X 30일치, Y1 30일치) : 임의의 회귀분석 모델 model을 30일치 데이터로 학습\n",
    "2. model.predict(X 3일치) : 학습시킨 모델에 X 3일치 데이터로 Y1 3일치 데이터 예측\n",
    "3. Y1,Y2의 3일치 432개 데이터가 준비됨. \n",
    "model2.fit(Y1 3일치,Y2 3일치) : 기존의 model 아니고 새로운 new model을 학습\n",
    "4. model2.predict(Y1 30일치) : model2로 Y2, 즉 Y18의 30일치 데이터를 예측\n",
    "5. model3(Y1전체, Y2전체) : model3로 온전한 33일치 데이터를 학습\n",
    "** 우려되는 점 : new_model을 학습시킬 때 데이터가 432개만으로 학습하기 때문에 과대적합 우려\n",
    "--------------------------------------------------------------------------------\n",
    "- 제거한 X14.X16은 사실상 측정되지 않음.모두 값이 0이었으나...섣불리 빼지말자;;Robust 완전 실패\n",
    "```python\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    robustScaler = RobustScaler()\n",
    "    print(robustScaler.fit(train_data))\n",
    "    train_data_robustScaled = robustScaler.transform(train_data)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아아아 전처리 뭐 어쩌라고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling,model pipeline gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료\n",
    "\n",
    "## 앙상블\n",
    "- https://teddylee777.github.io/machine-learning/ensemble%EA%B8%B0%EB%B2%95%EC%97%90-%EB%8C%80%ED%95%9C-%EC%9D%B4%ED%95%B4%EC%99%80-%EC%A2%85%EB%A5%98-1\n",
    "## 시계열\n",
    "- https://www.machinelearningplus.com/time-series/time-series-analysis-python/\n",
    "- https://towardsdatascience.com/@actsusanli\n",
    "## multiclass\n",
    "- https://scikit-learn.org/stable/modules/multiclass.html#multiclass\n",
    "## GridSearch\n",
    "- https://teddylee777.github.io/machine-learning/grid-search-%EB%A1%9C-hyperparameter%EC%B5%9C%EC%A0%81%ED%99%94\n",
    "## 이상치 처리 : \n",
    "- https://mkjjo.github.io/python/2019/01/10/outlier.html,           \n",
    "- https://medium.com/@john_analyst/isolation-forest%EB%A5%BC-%ED%86%B5%ED%95%9C-%EC%9D%B4%EC%83%81%ED%83%90%EC%A7%80-%EB%AA%A8%EB%8D%B8-9b10b43eb4ac\n",
    "## Feature Selection :\n",
    "- https://wikidocs.net/16599\n",
    "- https://www.kaggle.com/harangdev/feature-selection\n",
    "## oversampling : \n",
    "- https://datascienceschool.net/view-notebook/c1a8dad913f74811ae8eef5d3bedc0c3/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평가 지표는 실제값과 1 미만의 차이에 대해서는 패널티를 주지 않는 MSE입니다. 센서의 측정오차로 인해, 1 미만의 차이로 예측을 한 값에 대해서는 패널티를 부여하지 않습니다. \n",
    "A. 가채점 순위 (Public Score) : test 데이터의 50% 데이터로 채점합니다.\n",
    "B. 최종 순위 (Private Score) : Public Score에서 사용하지 않은 나머지 50% 데이터로 채점합니다. 대회 기간 중에는 확인할 수 없으며, 대회 종료 후에 공개됩니다.\n",
    "```python\n",
    "import numpy as np\n",
    "def mse_AIFrenz(y_true, y_pred):\n",
    "    '''\n",
    "    y_true: 실제 값\n",
    "    y_pred: 예측 값\n",
    "    '''\n",
    "    diff = abs(y_true - y_pred)\n",
    "\n",
    "    less_then_one = np.where(diff < 1, 0, diff)\n",
    "\n",
    "    # multi-column일 경우에도 계산 할 수 있도록 np.average를 한번 더 씌움\n",
    "    score = np.average(np.average(less_then_one ** 2, axis = 0))\n",
    "\n",
    "    return score\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jinny Pak\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\six.py:31: FutureWarning:\n",
      "\n",
      "The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "\n",
      "C:\\Users\\Jinny Pak\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning:\n",
      "\n",
      "sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_AIFrenz(y_true, y_pred):\n",
    "    '''\n",
    "    y_true: 실제 값\n",
    "    y_pred: 예측 값\n",
    "    '''\n",
    "    diff = abs(y_true - y_pred)\n",
    "\n",
    "    less_then_one = np.where(diff < 1, 0, diff)\n",
    "\n",
    "    # multi-column일 경우에도 계산 할 수 있도록 np.average를 한번 더 씌움\n",
    "    score = np.average(np.average(less_then_one ** 2, axis = 0))\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = './0_DataSet/train.csv'\n",
    "test_file = './0_DataSet/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sub=pd.read_csv('sample_submission.csv')\n",
    "test=pd.read_csv(test_file)\n",
    "train=pd.read_csv(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1=train.iloc[:4320,1:41]\n",
    "X_train2=train.iloc[4320:,1:41]\n",
    "y_17=train.iloc[:4320,41:-1]\n",
    "y_18=train.iloc[4320:,59:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블 모델\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingRegressor.html?highlight=regressor#sklearn.ensemble.VotingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base-line 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "models=[\n",
    "    ('dt',DecisionTreeRegressor()), \n",
    "    ('rf',RandomForestRegressor()),\n",
    "    ('xgb',XGBRegressor()),\n",
    "    ('ab',AdaBoostRegressor()),\n",
    "    ('br',BaggingRegressor()),\n",
    "    ('gb',GradientBoostingRegressor()),\n",
    "    ('sv',SVR()),\n",
    "    ('lgbm',LGBMRegressor()),\n",
    "    ('kn', KNeighborsRegressor()),\n",
    "    ('ridge',Ridge()),\n",
    "    ('lasso',Lasso())\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputRegressor(estimator=VotingRegressor(estimators=[('dt',\n",
       "                                                            DecisionTreeRegressor(ccp_alpha=0.0,\n",
       "                                                                                  criterion='mse',\n",
       "                                                                                  max_depth=None,\n",
       "                                                                                  max_features=None,\n",
       "                                                                                  max_leaf_nodes=None,\n",
       "                                                                                  min_impurity_decrease=0.0,\n",
       "                                                                                  min_impurity_split=None,\n",
       "                                                                                  min_samples_leaf=1,\n",
       "                                                                                  min_samples_split=2,\n",
       "                                                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                                                  presort='deprecated',\n",
       "                                                                                  random_state=None,\n",
       "                                                                                  splitter='best')),\n",
       "                                                           ('rf'...\n",
       "                                                           ('ridge',\n",
       "                                                            Ridge(alpha=1.0,\n",
       "                                                                  copy_X=True,\n",
       "                                                                  fit_intercept=True,\n",
       "                                                                  max_iter=None,\n",
       "                                                                  normalize=False,\n",
       "                                                                  random_state=None,\n",
       "                                                                  solver='auto',\n",
       "                                                                  tol=0.001)),\n",
       "                                                           ('lasso',\n",
       "                                                            Lasso(alpha=1.0,\n",
       "                                                                  copy_X=True,\n",
       "                                                                  fit_intercept=True,\n",
       "                                                                  max_iter=1000,\n",
       "                                                                  normalize=False,\n",
       "                                                                  positive=False,\n",
       "                                                                  precompute=False,\n",
       "                                                                  random_state=None,\n",
       "                                                                  selection='cyclic',\n",
       "                                                                  tol=0.0001,\n",
       "                                                                  warm_start=False))],\n",
       "                                               n_jobs=None, weights=None),\n",
       "                     n_jobs=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X-> Y00~17 학습 모델\n",
    "vote  = VotingRegressor(models)\n",
    "multi_model=MultiOutputRegressor(vote)\n",
    "multi_model.fit(X_train1,y_17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3일간의 Y00~17 예측값\n",
    "pred_y17=multi_model.predict(X_train2)\n",
    "pred_y17_df=pd.DataFrame(pred_y17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9408d2385c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Y00~17 3일간의 예측값 -\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvote2\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mVotingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmulti_model2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMultiOutputRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvote\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmulti_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_y17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vote' is not defined"
     ]
    }
   ],
   "source": [
    "# Y00~17 3일간의 예측값 -> Y18 3일 학습\n",
    "vote2  = VotingRegressor(models)\n",
    "multi_model2=MultiOutputRegressor(vote2)\n",
    "multi_model2.fit(pred_y17,y_18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 제출할 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.960984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.270790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.988945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.886526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.643114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>26.538323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>26.889662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11517</th>\n",
       "      <td>26.821821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11518</th>\n",
       "      <td>26.285530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11519</th>\n",
       "      <td>26.424193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11520 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0\n",
       "0      19.960984\n",
       "1      20.270790\n",
       "2      19.988945\n",
       "3      19.886526\n",
       "4      19.643114\n",
       "...          ...\n",
       "11515  26.538323\n",
       "11516  26.889662\n",
       "11517  26.821821\n",
       "11518  26.285530\n",
       "11519  26.424193\n",
       "\n",
       "[11520 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test -> Y00~17 예측\n",
    "pred_test=multi_model.predict(test.iloc[:,1:])\n",
    "pred_test_df=pd.DataFrame(pred_test)\n",
    "\n",
    "# Y00~17 -> Y18 예측\n",
    "pred_test2=multi_model2.predict(pred_test_df)\n",
    "pred_test_df2=pd.DataFrame(pred_test2)\n",
    "pred_test_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
